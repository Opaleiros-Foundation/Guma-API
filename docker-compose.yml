services:
  db:
    image: postgres
    restart: always
    hostname: db
    environment:
      - POSTGRES_PASSWORD=123
      - POSTGRES_DB=guma
    ports:
      - "5431:5431"
    healthcheck:
      test: [ "CMD-SHELL", "psql -h localhost -U postgres -d guma -c 'SELECT 1;'" ]
      interval: 5s
      timeout: 5s
      retries: 20
      start_period: 10s
    volumes:
      - ./.docker/db/data:/var/lib/postgresql/:delegated
    networks:
      - mynetwork

  api:
    image: matheusvict/gumaapi:latest
    hostname: api
    environment:
      - SPRING.PROFILES.ACTIVE=prod
      - PGHOST=db
      - PGPORT=5432
      - PGDATABASE=guma
      - PGUSER=postgres
      - PGPASSWORD=123
      - SPRING.AI.OLLAMA.USERNAME=api
      - SPRING.AI.OLLAMA.PASSWORD=api
      - OLLAMA_BASE_URL=http://ollama:11434
      - OLLAMA_MODEL=tinyllama
      - APPLICATION_PREFIX=/api/v1/guma
      - CORS_ALLOWED_ORIGINS=http://client:3000
    ports:
      - "8080:8080"
    depends_on:
      db:
        condition: service_healthy
      ollama:
        condition: service_started
    networks:
      - mynetwork
    healthcheck:
      test: [ "CMD-SHELL", "curl --fail http://localhost:8080/actuator/health || exit 1" ]
      interval: 30s
      timeout: 10s
      retries: 3


  client:
    image: matheusvict/gumaclient:latest
    hostname: client
    environment:
      - BASE_URL_SERVER=api
    ports:
      - "3000:80"
    depends_on:
      - api
    networks:
      - mynetwork
  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - .:/code
      - ./ollama/ollama:/root/.ollama
    container_name: ollama
    pull_policy: always
    tty: true
    restart: always
    environment:
      - OLLAMA_KEEP_ALIVE=24h
      - OLLAMA_HOST=0.0.0.0:11434
      - OLLAMA_USERNAME=api
      - OLLAMA_PASSWORD=api
    entrypoint: [ "/bin/sh", "-c", "ollama serve & sleep 5 && ollama pull tinyllama && while true; do echo $$; sleep 1; done" ]
    networks:
      - mynetwork

networks:
  mynetwork:
    driver: bridge

volumes:
  ollama_volume: